{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import lag_plot\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cProfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_symbols(base_dir=\"data\"):\n",
    "    \"\"\"Return a list of symbols from a directory by removing the file extension `csv`.\"\"\"\n",
    "    file_list = os.listdir(base_dir)\n",
    "    res =[]\n",
    "\n",
    "    for file in file_list:\n",
    "        file = file.split('.')\n",
    "        if file[1] ==\"csv\":\n",
    "            res.append(file[0])\n",
    "    return res\n",
    "        \n",
    "def symbol_to_path(symbol, base_dir= \"data\"):\n",
    "    \"\"\"Return CSV file path given ticker symbol.\"\"\"\n",
    "    return os.path.join(base_dir, \"{}.csv\".format(str(symbol)))\n",
    "\n",
    "def get_data(symbols, dates):\n",
    "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
    "    df_container = pd.DataFrame(index=dates)\n",
    "    if 'SPY' not in symbols:  # add SPY for reference, if absent\n",
    "        symbols.insert(0, 'SPY')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    if len(symbols) > 1:\n",
    "        for symbol in symbols:\n",
    "            if symbol == \"SPY\":\n",
    "                df_temp = pd.read_csv(\"data/\" + \"SPY\" + \".csv\", index_col= \"Date\", parse_dates= True, usecols=['Date', 'Adj Close'], na_values=\"nan\")\n",
    "                df_temp = df_temp.rename(columns={'Adj Close':\"SPY\"})\n",
    "                df_container = df_container.join(df_temp)\n",
    "                df_container = df_container.dropna();\n",
    "            else:\n",
    "            \n",
    "                df_temp = pd.read_csv(\"data/\" + symbol + \".csv\", index_col= \"Date\", parse_dates= True, usecols=['Date', 'Adj Close'], na_values=\"nan\")\n",
    "                df_temp = df_temp.rename(columns={'Adj Close':symbol})\n",
    "                df_container = df_container.join(df_temp)\n",
    "    else:\n",
    "        df_temp = pd.read_csv(\"data/\" + symbols[0] + \".csv\", index_col= \"Date\", parse_dates= True, usecols=['Date', 'Adj Close'], na_values=\"nan\")\n",
    "        df_temp = df_temp.rename(columns={'Adj Close':symbols[0]})\n",
    "        df_container = df_container.join(df_temp)\n",
    "\n",
    "    return df_container\n",
    "\n",
    "def normalise_data(df:pd.DataFrame, frame_of_reference= 0):\n",
    "    \"\"\"Normalises the data based on the frame of reference\"\"\"\n",
    "    return df/df.iloc[frame_of_reference]\n",
    "\n",
    "def get_rolling_mean(df:pd.DataFrame, window = 20):\n",
    "    return df.rolling(window).mean()\n",
    "\n",
    "def get_rolling_std(df:pd.DataFrame, window = 20):\n",
    "    return df.rolling(window).std()\n",
    "\n",
    "def get_bollinger_bands(df:pd.DataFrame, window = 20, num_std = 2):\n",
    "    \"\"\" Returns a tuple of Bollinger BandsÂ® `(upper band, rolling mean , lower band)`\"\"\"\n",
    "\n",
    "    rolling_mean = get_rolling_mean(df, window)\n",
    "    std = get_rolling_std(df, window)\n",
    "    upper_band = rolling_mean + num_std * std\n",
    "    lower_band = rolling_mean - num_std * std\n",
    "\n",
    "    return (upper_band, rolling_mean, lower_band)\n",
    "\n",
    "def get_daily_returns(df:pd.DataFrame):\n",
    "    df_lag = df.shift(1)\n",
    "    df_res = ((df/df_lag) - 1) * 100\n",
    "\n",
    "    df_res = df_res.fillna(0)\n",
    "\n",
    "    return df_res\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df.ffill(axis=0, inplace=True)\n",
    "    df.bfill(axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressors/Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear\n",
    "def create_regression(df:pd.DataFrame, window=100):\n",
    "    \"\"\"\n",
    "    `df`dataframe to create regression from \\n\n",
    "    `window` the number of days from the dataframe to consider in the regression\n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO: make this seperate every col in df and create its regression individually\n",
    "    res = df.tail(window)\n",
    "    res = res.reset_index(drop=True, inplace=False)\n",
    "    res.insert(0, 'index',res.index)\n",
    "    temp_array = res.to_numpy()\n",
    "    temp_array = np.transpose(temp_array) \n",
    "    \n",
    "    reg = lm.LinearRegression()\n",
    "    \n",
    "    reg.fit(temp_array[0].reshape(-1, 1) ,temp_array[1])\n",
    "\n",
    "    x = np.linspace(int(temp_array[0][0])+1, int(temp_array[0][-1])+1 + window, window+window+1)\n",
    "    b = reg.intercept_\n",
    "    m = reg.coef_\n",
    "    y = m * x + b\n",
    "    # print(temp_array[0][0])\n",
    "\n",
    "    # print(y)\n",
    "    # print(m)\n",
    "    # print(x)\n",
    "    # print(b)\n",
    "\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=window)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "\n",
    "\n",
    "    fin = df.tail(window)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "    fin.insert(0, \"regression\", y)\n",
    "    # fin.pop(\"SPY\")\n",
    "\n",
    "\n",
    "    return fin\n",
    "\n",
    "# poly\n",
    "def create_regression_2(df:pd.DataFrame, window=100, degree=3):\n",
    "    # TODO: make this seperate every col in df and create its regression individually\n",
    "    \n",
    "    # convert data to scikit-learn friendly format\n",
    "    res = df.tail(window)\n",
    "    res = res.reset_index(drop=True, inplace=False)\n",
    "    res.insert(0, 'index',res.index)\n",
    "    temp_array = res.to_numpy()\n",
    "    temp_array = np.transpose(temp_array) \n",
    "\n",
    "    x_train = temp_array[0]\n",
    "    y_train = temp_array[1]\n",
    "\n",
    "    # create poly features matrix\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_poly = poly_features.fit_transform(x_train.reshape(-1, 1))\n",
    "\n",
    "    # fit poly regression model\n",
    "    model = lm.LinearRegression()\n",
    "    model.fit(x_poly, y_train)\n",
    "\n",
    "\n",
    "    # use results / create predictions\n",
    "    x_test = np.linspace(int(temp_array[0][0])+1, int(temp_array[0][-1])+1 + window, window+window+1)\n",
    "    x_test_poly = poly_features.transform(x_test.reshape(-1, 1))\n",
    "    y_pred = model.predict(x_test_poly)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # move results to dataframe\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=window)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "    fin = df.tail(window)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "\n",
    "    fin.insert(0, \"regression\", y_pred)\n",
    "    # fin.pop(\"SPY\")\n",
    "\n",
    "\n",
    "    return fin\n",
    "\n",
    "# spline (interpolator)\n",
    "def create_regression_3(df:pd.DataFrame, window=100, knots=10):\n",
    "    \"\"\"\n",
    "    Spline regression, bad \n",
    "    \"\"\"\n",
    "\n",
    "    # convert data to scikit-learn friendly format\n",
    "    res = df.tail(window)\n",
    "    res = res.reset_index(drop=True, inplace=False)\n",
    "    res.insert(0, 'index',res.index)\n",
    "    temp_array = res.to_numpy()\n",
    "    temp_array = np.transpose(temp_array) \n",
    "\n",
    "    x_train = temp_array[0]\n",
    "    y_train = temp_array[1]\n",
    "\n",
    "    # Step 3: Create a spline features matrix\n",
    "    # knots = 3  # Set knot points, which divide the data into segments\n",
    "    spline_features = SplineTransformer(degree=3, n_knots=knots)\n",
    "    x_spline = spline_features.fit_transform(x_train.reshape(-1, 1))\n",
    "\n",
    "    # Step 4: Fit a linear regression model\n",
    "    model = lm.LinearRegression()\n",
    "    model.fit(x_spline, y_train)\n",
    "\n",
    "    # Step 5: Make predictions and visualize the results\n",
    "    x_test = np.linspace(int(temp_array[0][0])+1, int(temp_array[0][-1])+1 + window, window+window+1)  # Generate test data for prediction\n",
    "    x_test_spline = spline_features.transform(x_test.reshape(-1, 1))\n",
    "    y_pred = model.predict(x_test_spline)\n",
    "\n",
    "    # move results to dataframe\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=window)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "    fin = df.tail(window)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "\n",
    "    fin.insert(0, \"regression\", y_pred)\n",
    "    # fin.pop(\"SPY\")\n",
    "\n",
    "\n",
    "    return fin\n",
    "\n",
    "# ARIMA    \n",
    "def create_prediction(df:pd.DataFrame, p=10,d=2,q=5, days_to_predict = 30):\n",
    "\n",
    "    \n",
    "    # Step 3: Decompose the Time Series (optional)\n",
    "    decomposition = seasonal_decompose(df['SPY'], model='additive')\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    # Step 4: Stationarize the Data (if needed)\n",
    "\n",
    "    # Step 5: Choose a Forecasting Model (e.g., ARIMA)\n",
    "    model = ARIMA(df['SPY'], order=(p, d, q))  # Replace p, d, q with appropriate values\n",
    "\n",
    "    # Step 6: Train the Model\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Step 7: Make Forecasts\n",
    "    forecast_periods = days_to_predict  # Number of periods to forecast\n",
    "    forecast = model_fit.forecast(steps=forecast_periods)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Step 8: Visualize Forecasts\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(df.index, df['SPY'], label='Original Data')\n",
    "    # plt.plot(pd.date_range(start=df.index[-1], periods=forecast_periods+1), [df['SPY'].iloc[-1]] + list(forecast), label='Forecast', color='red')\n",
    "    # plt.title('Time Series Forecast')\n",
    "    # plt.xlabel('Date')\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # move results to dataframe\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=days_to_predict-1)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "    fin = df.tail(days_to_predict)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "    df_pred = pd.DataFrame(index=new_date_range)\n",
    "    df_pred.insert(0, \"regression\", forecast)\n",
    "\n",
    "\n",
    "\n",
    "    fin=fin.join(df_pred)\n",
    "\n",
    "    return fin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run():\n",
    "    # Define a date range\n",
    "    dates = pd.date_range('2010-03-01', '2010-04-29')\n",
    "    # dates = pd.date_range('2010-01-01', '2010-12-30')\n",
    "    # dates = pd.date_range('2006-01-01', '2013-12-30')\n",
    "\n",
    "    # Choose stock symbols to read\n",
    "    symbols = path_to_symbols()\n",
    "    print(symbols)\n",
    "    symbols = [symbols[4]]\n",
    "    \n",
    "    # data collection / clean-up\n",
    "    df = get_data(symbols, dates)\n",
    "    fill_missing_values(df)\n",
    "    \n",
    "    df = normalise_data(df)\n",
    "    window = 20\n",
    "    \n",
    "    # generating regression(s)\n",
    "    # reg_df = create_regression(df)      # linear reg\n",
    "    # reg_df_2 = create_regression_2(df)  # poly reg\n",
    "    # reg_df_3 = create_regression_3(df)  # spline reg\n",
    "    # ens_df = (reg_df_3 + reg_df_2 + reg_df)/3      # average of regs\n",
    "    pred = create_prediction(df, days_to_predict=100)\n",
    "\n",
    "    # df=df-1\n",
    "    # PLOTTING DATA\n",
    "    # ax = df.plot(title=\"normalised price\")\n",
    "    # ax.set_xlabel(\"Date\")\n",
    "    # ax.set_ylabel(\"Price\")\n",
    "\n",
    "    # bx = get_daily_returns(df).plot(title=\"daily returns\")\n",
    "    # bx.set_xlabel(\"Date\")\n",
    "    # bx.set_ylabel(\"Price\")\n",
    "\n",
    "    # cx = reg_df.plot(title=\"Predicted\")\n",
    "    # cx = reg_df_2.plot(label=\"Predicted\",ax=cx)\n",
    "    # cx = ens_df.plot(title=\"Predicted\")\n",
    "    # cx = ens_df.plot(label=\"Predicted\", ax=ax)\n",
    "\n",
    "    # dx = reg_df_3.plot(title=\"epic\")\n",
    "\n",
    "    bb = get_bollinger_bands(df, window)\n",
    "    # ub_df = bb[0]\n",
    "    rm_df = bb[1].shift(-10)\n",
    "    # lb_df = bb[2]\n",
    "    # ub_df.plot(label=\"upper mean\", ax=ax)\n",
    "    # rm_df.plot(ax=ax)\n",
    "    # lb_df.plot(label=\"lower mean\", ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_run()\n",
    "\n",
    "    # profile the performance of the code\n",
    "    # cProfile.run(\"test_run()\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_2(df:pd.DataFrame, p=4,d=1,q=0, num_days_to_predict =30):\n",
    "\n",
    "    # lag_plot(df[\"SPY\"], lag=3)\n",
    "\n",
    "\n",
    "    # Split data to training and test data 70% - 30%\n",
    "    training_data, test_data = df[0:int(len(df) * 0.7)], df[int(len(df) * 0.7):]\n",
    "\n",
    "    training_data = training_data.values\n",
    "    test_data = test_data.values\n",
    "\n",
    "    history = [x for x in training_data]\n",
    "    model_predictions = []\n",
    "\n",
    "    N_test_observations = len(test_data)  # Include the additional days in the loop\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for time_point in range(N_test_observations):\n",
    "        model = ARIMA(history, order=(p,d,q))\n",
    "        model_fit = model.fit()\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        model_predictions.append(yhat)\n",
    "        true_test_value = test_data[time_point]\n",
    "        history.append(true_test_value)\n",
    "        models.append(model_fit)\n",
    "\n",
    "    pred = models[-1].forecast(steps=num_days_to_predict)\n",
    "\n",
    "    MSE_error = mean_squared_error(test_data, model_predictions[:len(test_data)])\n",
    "    print('Testing Mean Squared Error is {}'.format(MSE_error))\n",
    "\n",
    "    test_set_range = df[int(len(df)*0.7):].index\n",
    "    # plt.plot(test_set_range, model_predictions, color='blue', marker='o', linestyle='dashed',label='Predicted Price')\n",
    "    # plt.plot(test_set_range, test_data, color='red', label='Actual Price')\n",
    "    # plt.title('TESLA Prices Prediction')\n",
    "    # plt.xlabel('Date')\n",
    "    # plt.ylabel('Prices')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # move results to dataframe\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=num_days_to_predict-1)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "    fin = df.tail(num_days_to_predict)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "    df_pred = pd.DataFrame(index=new_date_range)\n",
    "    df_pred.insert(0, \"regression\", pred)\n",
    "\n",
    "\n",
    "\n",
    "    fin=fin.join(df_pred)\n",
    "\n",
    "    return fin\n",
    "\n",
    "def experiment():\n",
    "    # Define a date range\n",
    "    dates = pd.date_range('2010-03-01', '2010-04-29')\n",
    "    # dates = pd.date_range('2010-01-01', '2010-12-30')\n",
    "    # dates = pd.date_range('2006-01-01', '2013-12-30')\n",
    "\n",
    "    # Choose stock symbols to read\n",
    "    symbols = path_to_symbols()\n",
    "    symbols = [symbols[4]]\n",
    "    \n",
    "    # data collection / clean-up\n",
    "    df = get_data(symbols, dates)\n",
    "    fill_missing_values(df)\n",
    "    \n",
    "    # df = normalise_data(df)\n",
    "    window = 20\n",
    "\n",
    "\n",
    "    days = 60\n",
    "    # for i in range(0,10):\n",
    "    # df_p_1 = create_prediction_2(df,p=10,d=2,q=5,num_days_to_predict=days)\n",
    "    # print(\"prediction1\")\n",
    "    # print(df_p_1)\n",
    "    # ax = df_p_1.plot(title=\"pred1\")\n",
    "\n",
    "\n",
    "    for i in range(0, 15):\n",
    "        df_p_2 = create_prediction(df,p=4,d=1,q=2,days_to_predict=days)\n",
    "        print(\"prediction2\")\n",
    "        print(df_p_2)\n",
    "        bx = df_p_2.plot(title=\"pred2\")\n",
    "    \n",
    "    # df_ensamble = (df_p_1+df_p_2)/2\n",
    "    # print(df_ensamble)\n",
    "    # cx = df_ensamble.plot(title=\"ensamble\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
