{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cProfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_symbols(base_dir=\"data\"):\n",
    "    \"\"\"Return a list of symbols from a directory by removing the file extension `csv`.\"\"\"\n",
    "    file_list = os.listdir(base_dir)\n",
    "    res =[]\n",
    "\n",
    "    for file in file_list:\n",
    "        file = file.split('.')\n",
    "        if file[1] ==\"csv\":\n",
    "            res.append(file[0])\n",
    "    return res\n",
    "        \n",
    "def symbol_to_path(symbol, base_dir= \"data\"):\n",
    "    \"\"\"Return CSV file path given ticker symbol.\"\"\"\n",
    "    return os.path.join(base_dir, \"{}.csv\".format(str(symbol)))\n",
    "\n",
    "def get_data(symbols, dates):\n",
    "    \"\"\"Read stock data (adjusted close) for given symbols from CSV files.\"\"\"\n",
    "    df_container = pd.DataFrame(index=dates)\n",
    "    if 'SPY' not in symbols:  # add SPY for reference, if absent\n",
    "        symbols.insert(0, 'SPY')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    if len(symbols) > 1:\n",
    "        for symbol in symbols:\n",
    "            if symbol == \"SPY\":\n",
    "                df_temp = pd.read_csv(\"data/\" + \"SPY\" + \".csv\", index_col= \"Date\", parse_dates= True, usecols=['Date', 'Adj Close'], na_values=\"nan\")\n",
    "                df_temp = df_temp.rename(columns={'Adj Close':\"SPY\"})\n",
    "                df_container = df_container.join(df_temp)\n",
    "                df_container = df_container.dropna();\n",
    "            else:\n",
    "            \n",
    "                df_temp = pd.read_csv(\"data/\" + symbol + \".csv\", index_col= \"Date\", parse_dates= True, usecols=['Date', 'Adj Close'], na_values=\"nan\")\n",
    "                df_temp = df_temp.rename(columns={'Adj Close':symbol})\n",
    "                df_container = df_container.join(df_temp)\n",
    "    else:\n",
    "        df_temp = pd.read_csv(\"data/\" + symbols[0] + \".csv\", index_col= \"Date\", parse_dates= True, usecols=['Date', 'Adj Close'], na_values=\"nan\")\n",
    "        df_temp = df_temp.rename(columns={'Adj Close':symbols[0]})\n",
    "        df_container = df_container.join(df_temp)\n",
    "\n",
    "    return df_container\n",
    "\n",
    "def normalise_data(df:pd.DataFrame, frame_of_reference= 0):\n",
    "    \"\"\"Normalises the data based on the frame of reference\"\"\"\n",
    "    return df/df.iloc[frame_of_reference]\n",
    "\n",
    "def get_rolling_mean(df:pd.DataFrame, window = 20):\n",
    "    return df.rolling(window).mean()\n",
    "\n",
    "def get_rolling_std(df:pd.DataFrame, window = 20):\n",
    "    return df.rolling(window).std()\n",
    "\n",
    "def get_bollinger_bands(df:pd.DataFrame, window = 20, num_std = 2):\n",
    "    \"\"\" Returns a tuple of Bollinger BandsÂ® `(upper band, rolling mean , lower band)`\"\"\"\n",
    "\n",
    "    rolling_mean = get_rolling_mean(df, window)\n",
    "    std = get_rolling_std(df, window)\n",
    "    upper_band = rolling_mean + num_std * std\n",
    "    lower_band = rolling_mean - num_std * std\n",
    "\n",
    "    return (upper_band, rolling_mean, lower_band)\n",
    "\n",
    "def get_daily_returns(df:pd.DataFrame):\n",
    "    df_lag = df.shift(1)\n",
    "    df_res = ((df/df_lag) - 1) * 100\n",
    "\n",
    "    df_res = df_res.fillna(0)\n",
    "\n",
    "    return df_res\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df.ffill(axis=0, inplace=True)\n",
    "    df.bfill(axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressors/Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear\n",
    "def create_regression(df:pd.DataFrame, window=100):\n",
    "    \"\"\"\n",
    "    `df`dataframe to create regression from \\n\n",
    "    `window` the number of days from the dataframe to consider in the regression\n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO: make this seperate every col in df and create its regression individually\n",
    "    res = df.tail(window)\n",
    "    res = res.reset_index(drop=True, inplace=False)\n",
    "    res.insert(0, 'index',res.index)\n",
    "    temp_array = res.to_numpy()\n",
    "    temp_array = np.transpose(temp_array) \n",
    "    \n",
    "    reg = lm.LinearRegression()\n",
    "    \n",
    "    reg.fit(temp_array[0].reshape(-1, 1) ,temp_array[1])\n",
    "\n",
    "    x = np.linspace(int(temp_array[0][0])+1, int(temp_array[0][-1])+1 + window, window+window+1)\n",
    "    b = reg.intercept_\n",
    "    m = reg.coef_\n",
    "    y = m * x + b\n",
    "    # print(temp_array[0][0])\n",
    "\n",
    "    # print(y)\n",
    "    # print(m)\n",
    "    # print(x)\n",
    "    # print(b)\n",
    "\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=window)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "\n",
    "\n",
    "    fin = df.tail(window)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "    fin.insert(0, \"regression\", y)\n",
    "    # fin.pop(\"SPY\")\n",
    "\n",
    "\n",
    "    return fin\n",
    "\n",
    "# poly\n",
    "def create_regression_2(df:pd.DataFrame, window=100, degree=3):\n",
    "    # TODO: make this seperate every col in df and create its regression individually\n",
    "    \n",
    "    # convert data to scikit-learn friendly format\n",
    "    res = df.tail(window)\n",
    "    res = res.reset_index(drop=True, inplace=False)\n",
    "    res.insert(0, 'index',res.index)\n",
    "    temp_array = res.to_numpy()\n",
    "    temp_array = np.transpose(temp_array) \n",
    "\n",
    "    x_train = temp_array[0]\n",
    "    y_train = temp_array[1]\n",
    "\n",
    "    # create poly features matrix\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    x_poly = poly_features.fit_transform(x_train.reshape(-1, 1))\n",
    "\n",
    "    # fit poly regression model\n",
    "    model = lm.LinearRegression()\n",
    "    model.fit(x_poly, y_train)\n",
    "\n",
    "\n",
    "    # use results / create predictions\n",
    "    x_test = np.linspace(int(temp_array[0][0])+1, int(temp_array[0][-1])+1 + window, window+window+1)\n",
    "    x_test_poly = poly_features.transform(x_test.reshape(-1, 1))\n",
    "    y_pred = model.predict(x_test_poly)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # move results to dataframe\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=window)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "    fin = df.tail(window)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "\n",
    "    fin.insert(0, \"regression\", y_pred)\n",
    "    # fin.pop(\"SPY\")\n",
    "\n",
    "\n",
    "    return fin\n",
    "\n",
    "# spline (interpolator)\n",
    "def create_regression_3(df:pd.DataFrame, window=100, knots=10):\n",
    "    \"\"\"\n",
    "    Spline regression, bad \n",
    "    \"\"\"\n",
    "\n",
    "    # convert data to scikit-learn friendly format\n",
    "    res = df.tail(window)\n",
    "    res = res.reset_index(drop=True, inplace=False)\n",
    "    res.insert(0, 'index',res.index)\n",
    "    temp_array = res.to_numpy()\n",
    "    temp_array = np.transpose(temp_array) \n",
    "\n",
    "    x_train = temp_array[0]\n",
    "    y_train = temp_array[1]\n",
    "\n",
    "    # Step 3: Create a spline features matrix\n",
    "    # knots = 3  # Set knot points, which divide the data into segments\n",
    "    spline_features = SplineTransformer(degree=3, n_knots=knots)\n",
    "    x_spline = spline_features.fit_transform(x_train.reshape(-1, 1))\n",
    "\n",
    "    # Step 4: Fit a linear regression model\n",
    "    model = lm.LinearRegression()\n",
    "    model.fit(x_spline, y_train)\n",
    "\n",
    "    # Step 5: Make predictions and visualize the results\n",
    "    x_test = np.linspace(int(temp_array[0][0])+1, int(temp_array[0][-1])+1 + window, window+window+1)  # Generate test data for prediction\n",
    "    x_test_spline = spline_features.transform(x_test.reshape(-1, 1))\n",
    "    y_pred = model.predict(x_test_spline)\n",
    "\n",
    "    # move results to dataframe\n",
    "    last_date = df.index[-1]\n",
    "    new_end_date = last_date + pd.DateOffset(days=window)\n",
    "    new_date_range = pd.date_range(start=last_date, end=new_end_date, freq='D')\n",
    "\n",
    "    fin = df.tail(window)\n",
    "    fin = pd.concat([fin, pd.DataFrame(index=new_date_range)])\n",
    "\n",
    "\n",
    "    fin.insert(0, \"regression\", y_pred)\n",
    "    # fin.pop(\"SPY\")\n",
    "\n",
    "\n",
    "    return fin\n",
    "\n",
    "# ARIMA    \n",
    "def create_prediction(df:pd.DataFrame, p=10,d=2,q=5):\n",
    "\n",
    "    df.plot()\n",
    "    plot_acf(df['SPY'].diff())\n",
    "    \n",
    "    # Step 3: Decompose the Time Series (optional)\n",
    "    decomposition = seasonal_decompose(df['SPY'], model='additive')\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    # Step 4: Stationarize the Data (if needed)\n",
    "\n",
    "    # Step 5: Choose a Forecasting Model (e.g., ARIMA)\n",
    "    model = ARIMA(df['SPY'], order=(p, d, q))  # Replace p, d, q with appropriate values\n",
    "\n",
    "    # Step 6: Train the Model\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Step 7: Make Forecasts\n",
    "    forecast_periods = 30  # Number of periods to forecast\n",
    "    forecast = model_fit.forecast(steps=forecast_periods)\n",
    "\n",
    "    \n",
    "    # Step 8: Visualize Forecasts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df.index, df['SPY'], label='Original Data')\n",
    "    plt.plot(pd.date_range(start=df.index[-1], periods=forecast_periods+1), [df['SPY'].iloc[-1]] + list(forecast), label='Forecast', color='red')\n",
    "    plt.title('Time Series Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "day is out of range for month: 2010-02-29",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:679\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: day is out of range for month",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO\\Desktop\\uni\\YEAR 4\\fall\\stock thing\\stock predictor\\main.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# lb_df = bb[2]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m# ub_df.plot(label=\"upper mean\", ax=ax)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# rm_df.plot(ax=ax)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m# lb_df.plot(label=\"lower mean\", ax=ax)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     test_run()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39m# profile the performance of the code\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m# cProfile.run(\"test_run()\")\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\Desktop\\uni\\YEAR 4\\fall\\stock thing\\stock predictor\\main.ipynb Cell 9\u001b[0m in \u001b[0;36mtest_run\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_run\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Define a date range\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dates \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mdate_range(\u001b[39m'\u001b[39;49m\u001b[39m2010-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2010-02-29\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# dates = pd.date_range('2010-01-01', '2010-12-30')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# dates = pd.date_range('2006-01-01', '2013-12-30')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Choose stock symbols to read\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/Desktop/uni/YEAR%204/fall/stock%20thing/stock%20predictor/main.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     symbols \u001b[39m=\u001b[39m path_to_symbols()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:945\u001b[0m, in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m com\u001b[39m.\u001b[39many_none(periods, start, end):\n\u001b[0;32m    943\u001b[0m     freq \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 945\u001b[0m dtarr \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39m_generate_range(\n\u001b[0;32m    946\u001b[0m     start\u001b[39m=\u001b[39mstart,\n\u001b[0;32m    947\u001b[0m     end\u001b[39m=\u001b[39mend,\n\u001b[0;32m    948\u001b[0m     periods\u001b[39m=\u001b[39mperiods,\n\u001b[0;32m    949\u001b[0m     freq\u001b[39m=\u001b[39mfreq,\n\u001b[0;32m    950\u001b[0m     tz\u001b[39m=\u001b[39mtz,\n\u001b[0;32m    951\u001b[0m     normalize\u001b[39m=\u001b[39mnormalize,\n\u001b[0;32m    952\u001b[0m     inclusive\u001b[39m=\u001b[39minclusive,\n\u001b[0;32m    953\u001b[0m     unit\u001b[39m=\u001b[39munit,\n\u001b[0;32m    954\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    955\u001b[0m )\n\u001b[0;32m    956\u001b[0m \u001b[39mreturn\u001b[39;00m DatetimeIndex\u001b[39m.\u001b[39m_simple_new(dtarr, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:404\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[0;32m    401\u001b[0m     start \u001b[39m=\u001b[39m Timestamp(start)\n\u001b[0;32m    403\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     end \u001b[39m=\u001b[39m Timestamp(end)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m NaT \u001b[39mor\u001b[39;00m end \u001b[39mis\u001b[39;00m NaT:\n\u001b[0;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNeither `start` nor `end` can be NaT\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\_libs\\tslibs\\timestamps.pyx:1667\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:280\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:557\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:329\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: day is out of range for month: 2010-02-29"
     ]
    }
   ],
   "source": [
    "def test_run():\n",
    "    # Define a date range\n",
    "    dates = pd.date_range('2010-01-01', '2010-02-29')\n",
    "    # dates = pd.date_range('2010-01-01', '2010-12-30')\n",
    "    # dates = pd.date_range('2006-01-01', '2013-12-30')\n",
    "\n",
    "    # Choose stock symbols to read\n",
    "    symbols = path_to_symbols()\n",
    "    print(symbols)\n",
    "    symbols = [symbols[4]]\n",
    "    \n",
    "    # data collection / clean-up\n",
    "    df = get_data(symbols, dates)\n",
    "    fill_missing_values(df)\n",
    "    \n",
    "    df = normalise_data(df)\n",
    "    window = 20\n",
    "    \n",
    "    # generating regression(s)\n",
    "    # reg_df = create_regression(df)      # linear reg\n",
    "    # reg_df_2 = create_regression_2(df)  # poly reg\n",
    "    # reg_df_3 = create_regression_3(df)  # spline reg\n",
    "    # ens_df = (reg_df_3 + reg_df_2 + reg_df)/3      # average of regs\n",
    "    pred = create_prediction(df)\n",
    "\n",
    "    # df=df-1\n",
    "    # PLOTTING DATA\n",
    "    # ax = df.plot(title=\"normalised price\")\n",
    "    # ax.set_xlabel(\"Date\")\n",
    "    # ax.set_ylabel(\"Price\")\n",
    "\n",
    "    # bx = get_daily_returns(df).plot(title=\"daily returns\")\n",
    "    # bx.set_xlabel(\"Date\")\n",
    "    # bx.set_ylabel(\"Price\")\n",
    "\n",
    "    # cx = reg_df.plot(title=\"Predicted\")\n",
    "    # cx = reg_df_2.plot(label=\"Predicted\",ax=cx)\n",
    "    # cx = ens_df.plot(title=\"Predicted\")\n",
    "    # cx = ens_df.plot(label=\"Predicted\", ax=ax)\n",
    "\n",
    "    # dx = reg_df_3.plot(title=\"epic\")\n",
    "\n",
    "    bb = get_bollinger_bands(df, window)\n",
    "    # ub_df = bb[0]\n",
    "    rm_df = bb[1].shift(-10)\n",
    "    # lb_df = bb[2]\n",
    "    # ub_df.plot(label=\"upper mean\", ax=ax)\n",
    "    # rm_df.plot(ax=ax)\n",
    "    # lb_df.plot(label=\"lower mean\", ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_run()\n",
    "\n",
    "    # profile the performance of the code\n",
    "    # cProfile.run(\"test_run()\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                    SPY   No. Observations:                   89\n",
      "Model:               ARIMA(10, 1, 10)   Log Likelihood                 -71.423\n",
      "Date:                Tue, 05 Sep 2023   AIC                            184.847\n",
      "Time:                        19:24:13   BIC                            236.871\n",
      "Sample:                    01-01-2010   HQIC                           205.806\n",
      "                         - 03-30-2010                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.0725      1.639      0.044      0.965      -3.139       3.284\n",
      "ar.L2          0.6804      1.249      0.545      0.586      -1.769       3.129\n",
      "ar.L3         -0.2019      0.603     -0.335      0.738      -1.384       0.980\n",
      "ar.L4         -0.1694      0.814     -0.208      0.835      -1.764       1.425\n",
      "ar.L5          0.0211      0.908      0.023      0.981      -1.758       1.800\n",
      "ar.L6          0.4955      1.003      0.494      0.621      -1.471       2.462\n",
      "ar.L7         -0.1021      0.585     -0.175      0.861      -1.248       1.044\n",
      "ar.L8         -0.6574      0.639     -1.029      0.303      -1.909       0.594\n",
      "ar.L9          0.3247      1.088      0.298      0.765      -1.809       2.458\n",
      "ar.L10         0.3276      0.670      0.489      0.625      -0.985       1.640\n",
      "ma.L1          0.1668      2.326      0.072      0.943      -4.392       4.725\n",
      "ma.L2         -0.8500      2.101     -0.405      0.686      -4.969       3.269\n",
      "ma.L3          0.0097      1.474      0.007      0.995      -2.880       2.899\n",
      "ma.L4          0.3859      1.316      0.293      0.769      -2.194       2.965\n",
      "ma.L5          0.0253      1.972      0.013      0.990      -3.839       3.890\n",
      "ma.L6         -0.3948      1.269     -0.311      0.756      -2.882       2.092\n",
      "ma.L7          0.1334      1.613      0.083      0.934      -3.029       3.296\n",
      "ma.L8          0.8510      1.340      0.635      0.525      -1.776       3.478\n",
      "ma.L9         -0.2237      2.432     -0.092      0.927      -4.991       4.543\n",
      "ma.L10        -0.8399      2.353     -0.357      0.721      -5.452       3.772\n",
      "sigma2         0.2695      0.441      0.611      0.541      -0.596       1.135\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                24.59\n",
      "Prob(Q):                              0.98   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.36   Skew:                            -0.77\n",
      "Prob(H) (two-sided):                  0.01   Kurtosis:                         5.09\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\miniconda3\\envs\\stock_pred\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "def analyse(df:pd.DataFrame, p=3,d=2,q=1):\n",
    "    result = adfuller(df.dropna())\n",
    "    result = adfuller(df.diff().dropna())\n",
    "\n",
    "    diff_df = df.diff().dropna()\n",
    "    # plot_acf(df)\n",
    "    # plot_acf(diff_df)\n",
    "\n",
    "\n",
    "    arima_model = ARIMA(df, order=(p,d,q))\n",
    "    model = arima_model.fit()\n",
    "    print(model.summary())\n",
    "    # arima_model.plot_predict(dynamic=False)\n",
    "\n",
    "    \n",
    "    return\n",
    "\n",
    "def experiment():\n",
    "    # Define a date range\n",
    "    dates = pd.date_range('2010-01-01', '2010-03-30')\n",
    "    # dates = pd.date_range('2010-01-01', '2010-12-30')\n",
    "    # dates = pd.date_range('2006-01-01', '2013-12-30')\n",
    "\n",
    "    # Choose stock symbols to read\n",
    "    symbols = path_to_symbols()\n",
    "    symbols = [symbols[4]]\n",
    "    \n",
    "    # data collection / clean-up\n",
    "    df = get_data(symbols, dates)\n",
    "    fill_missing_values(df)\n",
    "    \n",
    "    # df = normalise_data(df)\n",
    "    window = 20\n",
    "\n",
    "    # for i in range(0,10):\n",
    "    analyse(df,p=10,d=1,q=10)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment()\n",
    "\n",
    "    # profile the performance of the code\n",
    "    # cProfile.run(\"test_run()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
